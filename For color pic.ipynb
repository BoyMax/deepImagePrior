{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "from models import *\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from models.blindconvolution import BiConvolution\n",
    "\n",
    "from utils.sr_utils import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "#dtype = torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starts here\n",
    "#path_LR_image = 'data/sr/images/Cameraman256_gauss.png'\n",
    "#path_HR_image = 'data/sr/images/Cameraman256.png'\n",
    "kernel_path ='data/sr/images/kernel_gauss.png'\n",
    "img_k_pil, img_k_np = get_image(kernel_path, -1)\n",
    "#img_lr_pil, img_lr_np = get_image(path_LR_image, -1)\n",
    "#img_hr_pil, img_hr_np = get_image(path_HR_image, -1)\n",
    "#plot_image_grid([img_lr_np,img_hr_np])\n",
    "img_k_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_depth = 32\n",
    " \n",
    "INPUT =     'noise'\n",
    "pad   =     'reflection'\n",
    "OPT_OVER =  'net'\n",
    "KERNEL_TYPE='udf'\n",
    "\n",
    "LR = 0.01\n",
    "tv_weight = 0.0\n",
    "num_iter=10000\n",
    "reg_noise_std = 0.03\n",
    "\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "PLOT = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global i, net_input, net_input_kernel,info_dict,X,psnr_HR_max,K,psnr_k_max\n",
    "    \n",
    "    reg_noise_std = 0.01\n",
    "    net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    net_input_kernel = net_input_kernel + (noise_kernel.normal_() * reg_noise_std)\n",
    "\n",
    "    out_HR = net(net_input)\n",
    "    out_kernel = net_kernel(net_input_kernel)\n",
    "    #print(out_kernel.shape)\n",
    "    out_kernel = torch.nn.Softmax(2)(out_kernel.view(*out_kernel.size()[:2], -1)).view_as(out_kernel)\n",
    "    #print(out_kernel.shape)\n",
    "    padding = nn.ReflectionPad2d(4)\n",
    "    out_LR = torch.nn.functional.conv2d(padding(out_HR), out_kernel.expand(-1, out_HR.shape[1], -1, -1), padding=0)\n",
    "\n",
    "    total_loss = mse(out_LR, img_LR_var)\n",
    "    \n",
    "    if tv_weight > 0:\n",
    "        total_loss += tv_weight * tv_loss(out_HR)\n",
    "        \n",
    "    total_loss.backward()\n",
    "\n",
    "    # Log\n",
    "    print(img_lr_np.shape,torch_to_np(out_LR).shape)\n",
    "    psnr_LR = compare_psnr(img_lr_np, torch_to_np(out_LR))\n",
    "    psnr_HR = compare_psnr(img_hr_np, torch_to_np(out_HR))\n",
    "    psnr_k = compare_psnr(img_k_np, torch_to_np(out_kernel.view(1, 1, 9, 9)))\n",
    "    print ('Iteration %05d' % (i), '\\r', end='')\n",
    "                      \n",
    "    # History\n",
    "    psnr_history.append([psnr_LR, psnr_HR, psnr_k])\n",
    "    \n",
    "   # if PLOT and i % 100 == 0:\n",
    "        #out_HR_np = torch_to_np(out_HR)\n",
    "        #plot_image_grid([img_hr_np, np.clip(out_HR_np, 0, 1)], factor=13, nrow=3)\n",
    "    if psnr_HR > psnr_HR_max:\n",
    "        psnr_HR_max = psnr_HR\n",
    "        X = torch_to_np(out_HR)\n",
    "        K = torch_to_np(out_kernel)\n",
    "        psnr_k_max = psnr_k\n",
    "    \n",
    "    i += 1\n",
    "    if  i == num_iter:\n",
    "        info_dict = {'psnr_HR':psnr_HR_max,'psnr_k':psnr_k_max,'X': X,'K':K}\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization with ADAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Vivien/miniconda3/envs/dip/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/Vivien/miniconda3/envs/dip/lib/python3.6/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 256, 256) (1, 256, 256)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input images must have the same dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a41d01913a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mpsnr_HR_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# call network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# save result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepImagePrior/utils/common_utils.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(optimizer_type, parameters, closure, LR, num_iter)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d36f85dc2667>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_lr_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_LR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpsnr_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_lr_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_LR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mpsnr_HR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_hr_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_HR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mpsnr_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_k_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dip/lib/python3.6/site-packages/skimage/measure/simple_metrics.py\u001b[0m in \u001b[0;36mcompare_psnr\u001b[0;34m(im_true, im_test, data_range)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0m_assert_compatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_range\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dip/lib/python3.6/site-packages/skimage/measure/simple_metrics.py\u001b[0m in \u001b[0;36m_assert_compatible\u001b[0;34m(im1, im2)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"\"\"Raise an error if the shape and dtype do not match.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input images must have the same dimensions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input images must have the same dimensions."
     ]
    }
   ],
   "source": [
    "result = dict()\n",
    "for photo in ['image_House256rgb','image_Peppers512rgb']:\n",
    "    photo_dict = dict()\n",
    "    path_HR_image = 'data/sr/images/' + photo +'.png'\n",
    "    for kernel in ['gauss','motion','defocus']:#'gauss','motion','defocus'\n",
    "        if kernel == 'gauss':\n",
    "            kernel_path ='data/sr/kernels/kernel_gauss.mat'\n",
    "            path_LR_image = 'data/sr/images/'+ photo +'_gauss.png'\n",
    "        elif kernel == 'motion':\n",
    "            kernel_path ='data/sr/kernels/kernel_motionblur.mat'\n",
    "            path_LR_image = 'data/sr/images/'+ photo +'_motion.png'\n",
    "        elif kernel == 'defocus':\n",
    "            kernel_path ='data/sr/kernels/kernel_defocus.mat'\n",
    "            path_LR_image = 'data/sr/images/'+ photo +'_defocus.png'\n",
    "        else:\n",
    "            print('no image in kernel.')\n",
    "        \n",
    "        #continue when there is no file:\n",
    "        if os.path.isfile(path_LR_image) == False:\n",
    "            continue\n",
    "        ## load images\n",
    "        img_lr_pil, img_lr_np = get_image(path_LR_image, -1)\n",
    "        img_hr_pil, img_hr_np = get_image(path_HR_image, -1)\n",
    "        n_channels = img_hr_np.shape[0]\n",
    "        \n",
    "        net_input = get_noise(input_depth, INPUT, (img_hr_pil.size[1], img_hr_pil.size[0])).type(dtype).detach()\n",
    "        net_input_kernel= get_noise(input_depth, INPUT, (img_k_pil.size[1], img_k_pil.size[0])).type(dtype).detach()\n",
    "\n",
    "\n",
    "        NET_TYPE = 'skip' # UNet, ResNet\n",
    "        net = get_net(input_depth, 'skip', pad, n_channels=3, skip_n33d=128, skip_n33u=128, skip_n11=4, \n",
    "              num_scales=5, upsample_mode='bilinear').type(dtype)\n",
    "        net_kernel = biget_net(input_depth, 'skip', pad, n_channels=1, skip_n33d=128, skip_n33u=128, skip_n11=4, \n",
    "              num_scales=5, upsample_mode='bilinear').type(dtype)\n",
    "        mse = torch.nn.MSELoss().type(dtype)\n",
    "        img_LR_var = np_to_torch(img_lr_np).type(dtype)\n",
    "        img_k_var = np_to_torch(img_k_np).type(dtype)\n",
    "             \n",
    "        psnr_history = [] \n",
    "        net_input_saved = net_input.detach().clone()\n",
    "        net_input_kernel_saved = net_input_kernel.detach().clone()\n",
    "        noise = net_input.detach().clone()\n",
    "        noise_kernel = net_input_kernel.clone()\n",
    "\n",
    "        i = 0\n",
    "        p = get_params(OPT_OVER, net, net_input) + get_params(OPT_OVER, net_kernel, net_input_kernel)\n",
    "        mse_arr = np.zeros(num_iter)\n",
    "        info_dict = dict()\n",
    "        X = 0\n",
    "        K = 0\n",
    "        psnr_HR_max = 0\n",
    "        # call network\n",
    "        optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
    "        \n",
    "        # save result\n",
    "        kernel_dict = dict()\n",
    "        kernel_dict['info'] = info_dict\n",
    "        photo_dict[kernel] = kernel_dict\n",
    "        result[photo]=photo_dict\n",
    "        np.save('result_blind'+photo+kernel+'.npy',result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
